{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Base T5.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d55c5ae2ba73490586cebe59f27a573c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c3afea0c9bfb444e82396d6f7c5efe59","IPY_MODEL_9f9aff1ff282453aa802678d0b40094b","IPY_MODEL_a4915d02b5774bf7b3d4f0cb6b3d30f6"],"layout":"IPY_MODEL_3220cada88924d5fbd505823fdbd79e5"}},"c3afea0c9bfb444e82396d6f7c5efe59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2dbe94a86c9b43daa6dd09fbfd520535","placeholder":"​","style":"IPY_MODEL_0df12bec466e43a79c4b436cf4124e23","value":"100%"}},"9f9aff1ff282453aa802678d0b40094b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_da31dfe5e3044b8cad31f08b51bd9015","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56721128986149a6b759b827c7b0c329","value":12}},"a4915d02b5774bf7b3d4f0cb6b3d30f6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aa949acdd2747fcaf5a3ba477b10fec","placeholder":"​","style":"IPY_MODEL_059a7ef5fa9544b6a2f9c28ff0b3a48b","value":" 12/12 [00:15&lt;00:00,  1.33s/ba]"}},"3220cada88924d5fbd505823fdbd79e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dbe94a86c9b43daa6dd09fbfd520535":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0df12bec466e43a79c4b436cf4124e23":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"da31dfe5e3044b8cad31f08b51bd9015":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56721128986149a6b759b827c7b0c329":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8aa949acdd2747fcaf5a3ba477b10fec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"059a7ef5fa9544b6a2f9c28ff0b3a48b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wxMgDKwtS6_h"},"outputs":[],"source":["%%capture\n","!pip install --upgrade transformers\n","!pip install datasets\n","!pip install rouge_score\n","!pip install rouge"]},{"cell_type":"code","source":["import transformers\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n","from datasets import load_dataset, load_metric, Dataset\n","import torch\n","import numpy as np\n","import pandas as pd\n","import io\n","import math\n","import time"],"metadata":{"id":"Jdw70MvRTsQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GW9u4adqTs6P","outputId":"378eec44-d6cd-44e1-a65c-a57fce146532"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/Colab Notebooks/CSC413/amazon_review_dataset_processed.csv\"\n","df = pd.read_csv(path)\n","amazon = Dataset.from_pandas(df)\n","amazon.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWwa-wuiUMSZ","outputId":"ca85c9e8-442b-4f8a-e3e0-43a2a6fb7d13"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(11848, 3)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained('t5-base')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5c2vg-hTXFeo","outputId":"09e5ccdf-2bd3-4309-8795-c0ff60d3ae27"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Could not locate the tokenizer configuration file, will try to use the model config instead.\n","loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n","Model config T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading file https://huggingface.co/t5-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/684a47ca6257e4ca71f0037771464c5b323e945fbc58697d2fad8a7dd1a2f8ba.3b69006860e7b5d0a63ffdddc01ddcd6b7c318a6f4fd793596552c741734c62d\n","loading file https://huggingface.co/t5-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/90de37880b5ff5ac7ab70ff0bd369f207e9b74133fa153c163d14c5bb0116207.8627f1bd5d270a9fd2e5a51c8bec3223896587cc3cfe13edeabb0992ab43c529\n","loading file https://huggingface.co/t5-base/resolve/main/added_tokens.json from cache at None\n","loading file https://huggingface.co/t5-base/resolve/main/special_tokens_map.json from cache at None\n","loading file https://huggingface.co/t5-base/resolve/main/tokenizer_config.json from cache at None\n","loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n","Model config T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n"]}]},{"cell_type":"code","source":["task_prefix = \"summarize: \"\n","max_source_length = 512\n","max_target_length = 175\n","\n","def preprocess_function(reviews):\n","  input_sequences = reviews['reviewText']\n","  inputs = [task_prefix + sequence for sequence in input_sequences]\n","  model_inputs = tokenizer(inputs, max_length=max_source_length, truncation=True, padding=True)\n","\n","  summaries = reviews['summary']\n","  labels = tokenizer(summaries, max_length=max_target_length, truncation=True, padding=True)\n","\n","  model_inputs['labels'] = labels['input_ids']\n","  return model_inputs"],"metadata":{"id":"ZS4x1eObXKAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenized_amazon = amazon.map(preprocess_function, batched=True)\n","\n","\n","NotTest_Test = tokenized_amazon.train_test_split(test_size=0.1, shuffle=True, seed=42)\n","NotTest = NotTest_Test[\"train\"]\n","test = NotTest_Test[\"test\"]\n","\n","Train_Val = NotTest.train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train = Train_Val[\"train\"]\n","val = Train_Val[\"test\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["d55c5ae2ba73490586cebe59f27a573c","c3afea0c9bfb444e82396d6f7c5efe59","9f9aff1ff282453aa802678d0b40094b","a4915d02b5774bf7b3d4f0cb6b3d30f6","3220cada88924d5fbd505823fdbd79e5","2dbe94a86c9b43daa6dd09fbfd520535","0df12bec466e43a79c4b436cf4124e23","da31dfe5e3044b8cad31f08b51bd9015","56721128986149a6b759b827c7b0c329","8aa949acdd2747fcaf5a3ba477b10fec","059a7ef5fa9544b6a2f9c28ff0b3a48b"]},"id":"LNXYm3-tXXN4","outputId":"c821cae5-63be-47ef-997c-e272bac17f73"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/12 [00:00<?, ?ba/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d55c5ae2ba73490586cebe59f27a573c"}},"metadata":{}}]},{"cell_type":"code","source":["model = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n","torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = model.to(torch_device)\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUgJaxnpX82R","outputId":"0e9251b8-908c-4d38-df1d-6c7b2625499f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file https://huggingface.co/t5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/91e9fe874e06c44883b535d6c950b8b89d6eaa3298d8e7fb3b2c78039e9f8b7b.66b9637a52aa11e9285cdd6e668cc0df14b3bcf0b6674cf3ba5353c542649637\n","Model config T5Config {\n","  \"_name_or_path\": \"t5-base\",\n","  \"architectures\": [\n","    \"T5WithLMHeadModel\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file https://huggingface.co/t5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ab4e948915b067f5cb6e5105f6f85044fd717b133f43240db67899a8fc7b29a2.26934c75adf19ceac3c268b721ba353356b7609c45f5627550326f275a2163b4\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"]}]},{"cell_type":"code","source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir = \"./results\",\n","    evaluation_strategy = 'epoch',\n","    learning_rate = 2e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=3,\n","    fp16=True,\n","    predict_with_generate=True\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model = model,\n","    args = training_args,\n","    train_dataset = train,\n","    eval_dataset = val,\n","    tokenizer = tokenizer,\n","    data_collator = data_collator\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bOTfnKFLYv2I","outputId":"ab2cce22-65e8-408e-8d5c-c7f2efaa596b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","Using amp half precision backend\n","The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Unnamed: 0, reviewText, summary. If Unnamed: 0, reviewText, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 9596\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3600\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3600/3600 44:34, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.328800</td>\n","      <td>1.229451</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.278900</td>\n","      <td>1.208532</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>1.251800</td>\n","      <td>1.204258</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./results/checkpoint-500\n","Configuration saved in ./results/checkpoint-500/config.json\n","Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2500] due to args.save_total_limit\n","Saving model checkpoint to ./results/checkpoint-1000\n","Configuration saved in ./results/checkpoint-1000/config.json\n","Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-1000/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-1000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3000] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Unnamed: 0, reviewText, summary. If Unnamed: 0, reviewText, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1067\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-1500\n","Configuration saved in ./results/checkpoint-1500/config.json\n","Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-1500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-1500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-3500] due to args.save_total_limit\n","Saving model checkpoint to ./results/checkpoint-2000\n","Configuration saved in ./results/checkpoint-2000/config.json\n","Model weights saved in ./results/checkpoint-2000/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-2000/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-2000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Unnamed: 0, reviewText, summary. If Unnamed: 0, reviewText, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1067\n","  Batch size = 8\n","Saving model checkpoint to ./results/checkpoint-2500\n","Configuration saved in ./results/checkpoint-2500/config.json\n","Model weights saved in ./results/checkpoint-2500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-2500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-2500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n","Saving model checkpoint to ./results/checkpoint-3000\n","Configuration saved in ./results/checkpoint-3000/config.json\n","Model weights saved in ./results/checkpoint-3000/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-3000/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-3000/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n","Saving model checkpoint to ./results/checkpoint-3500\n","Configuration saved in ./results/checkpoint-3500/config.json\n","Model weights saved in ./results/checkpoint-3500/pytorch_model.bin\n","tokenizer config file saved in ./results/checkpoint-3500/tokenizer_config.json\n","Special tokens file saved in ./results/checkpoint-3500/special_tokens_map.json\n","Deleting older checkpoint [results/checkpoint-2000] due to args.save_total_limit\n","The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: Unnamed: 0, reviewText, summary. If Unnamed: 0, reviewText, summary are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 1067\n","  Batch size = 8\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3600, training_loss=1.3595966890123155, metrics={'train_runtime': 2675.0139, 'train_samples_per_second': 10.762, 'train_steps_per_second': 1.346, 'total_flos': 1.753067975344128e+16, 'train_loss': 1.3595966890123155, 'epoch': 3.0})"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["trainer.save_model(\"./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5\")"],"metadata":{"id":"tIh7oQF8a-Ex","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3b35e873-1ef9-48ec-cfa7-baa8f7331a21"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5\n","Configuration saved in ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5/config.json\n","Model weights saved in ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5/pytorch_model.bin\n","tokenizer config file saved in ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5/tokenizer_config.json\n","Special tokens file saved in ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5/special_tokens_map.json\n"]}]},{"cell_type":"code","source":["finetuned = AutoModelForSeq2SeqLM.from_pretrained(\"./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5\")"],"metadata":{"id":"LEe9cFYEe2_E","colab":{"base_uri":"https://localhost:8080/"},"outputId":"be9334c7-52a8-4d14-a250-3e2e530fe392"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5/config.json\n","Model config T5Config {\n","  \"_name_or_path\": \"./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5\",\n","  \"architectures\": [\n","    \"T5ForConditionalGeneration\"\n","  ],\n","  \"d_ff\": 3072,\n","  \"d_kv\": 64,\n","  \"d_model\": 768,\n","  \"decoder_start_token_id\": 0,\n","  \"dropout_rate\": 0.1,\n","  \"eos_token_id\": 1,\n","  \"feed_forward_proj\": \"relu\",\n","  \"initializer_factor\": 1.0,\n","  \"is_encoder_decoder\": true,\n","  \"layer_norm_epsilon\": 1e-06,\n","  \"model_type\": \"t5\",\n","  \"n_positions\": 512,\n","  \"num_decoder_layers\": 12,\n","  \"num_heads\": 12,\n","  \"num_layers\": 12,\n","  \"output_past\": true,\n","  \"pad_token_id\": 0,\n","  \"relative_attention_max_distance\": 128,\n","  \"relative_attention_num_buckets\": 32,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 200,\n","      \"min_length\": 30,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4,\n","      \"prefix\": \"summarize: \"\n","    },\n","    \"translation_en_to_de\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to German: \"\n","    },\n","    \"translation_en_to_fr\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to French: \"\n","    },\n","    \"translation_en_to_ro\": {\n","      \"early_stopping\": true,\n","      \"max_length\": 300,\n","      \"num_beams\": 4,\n","      \"prefix\": \"translate English to Romanian: \"\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.18.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32128\n","}\n","\n","loading weights file ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5/pytorch_model.bin\n","All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n","\n","All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at ./content/drive/MyDrive/Colab Notebooks/CSC413/baseT5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"]}]},{"cell_type":"code","source":["generated_summaries = []"],"metadata":{"id":"XQ8vp1wC-ka9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = torch.Tensor(test['input_ids']).long()\n","output_batch_size = 20\n","num_of_generate_loops=10\n","\n","for l in range(num_of_generate_loops):\n","  print(\"In loop number: \", l)\n","  current_batch = x[l*output_batch_size:(l+1)*output_batch_size]\n","  start = time.time()\n","  outputs = finetuned.generate(current_batch, max_length=25, min_length=2, num_beams = 2, repetition_penalty = 2.5, early_stopping=True)\n","  print(\"Loop : \", l, \"took: \", time.time() - start, \"to run\")\n","  decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","  generated_summaries.append(decoded_outputs)"],"metadata":{"id":"SYxGRdIt8xwO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ddde5f6-eeca-445d-a896-e7a4869e6afb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In loop number:  0\n","Loop :  0 took:  37.603630781173706 to run\n","In loop number:  1\n","Loop :  1 took:  36.88216710090637 to run\n","In loop number:  2\n","Loop :  2 took:  37.01695489883423 to run\n","In loop number:  3\n","Loop :  3 took:  36.91552209854126 to run\n","In loop number:  4\n","Loop :  4 took:  36.81117630004883 to run\n","In loop number:  5\n","Loop :  5 took:  36.77254104614258 to run\n","In loop number:  6\n","Loop :  6 took:  36.767659187316895 to run\n","In loop number:  7\n","Loop :  7 took:  36.907158613204956 to run\n","In loop number:  8\n","Loop :  8 took:  36.80144381523132 to run\n","In loop number:  9\n","Loop :  9 took:  36.92261624336243 to run\n"]}]},{"cell_type":"code","source":["flattened_outputs = np.array(generated_summaries).flatten()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nQh-3_saBJiX","outputId":"67e0ac4a-3bd9-4dae-c3b3-606666f7bbeb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["200"]},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["df_result = pd.DataFrame({'review':test['reviewText'][:200],'generated_summaries':flattened_outputs,'target_summaries':test['summary'][:200]})\n","df_result.to_csv('./content/drive/MyDrive/Colab Notebooks/CSC413/base_T5_outputs.csv') "],"metadata":{"id":"NhFG2i2KTEuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["metric = load_metric('rouge')\n","\n","def calc_rouge_scores(candidates, references):\n","    result = metric.compute(predictions=candidates, references=references, use_stemmer=True)\n","    result = {key: round(value.mid.fmeasure * 100, 1) for key, value in result.items()}\n","    return result\n","\n","calc_rouge_scores(flattened_outputs, test['summary'][:200])"],"metadata":{"id":"ixxSPUxgTIVd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4464b3c4-3c61-45bf-cf1d-b2f2585b80d8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'rouge1': 17.1, 'rouge2': 6.5, 'rougeL': 15.3, 'rougeLsum': 15.3}"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","source":[""],"metadata":{"id":"x684qeg8PCSy"},"execution_count":null,"outputs":[]}]}